{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as grid\n",
    "\n",
    "import priors\n",
    "from autoencoder import Encoder, Decoder\n",
    "\n",
    "from includes.config import Config\n",
    "from includes.utils import load_data, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xav_init = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loading Data and Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datagroup = \"mnist\"\n",
    "dataset = \"binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = Config(datagroup)\n",
    "\n",
    "train_data, test_data = load_data(datagroup, dataset=dataset)\n",
    "\n",
    "train_data = Dataset(train_data, batch_size=config.batch_size)\n",
    "test_data = Dataset(test_data, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if datagroup == \"spiral\":\n",
    "    plt.scatter(train_data.data[:, 0], train_data.data[:, 1], s=0.5)\n",
    "elif datagroup == \"mnist\":\n",
    "    images = train_data.data[np.random.choice(len(train_data), 100)]\n",
    "    \n",
    "    images = images.reshape((100, 28, 28))\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    images = np.array([images[:, x:x+280] for x in range(0, 2800, 280)])\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    images = np.concatenate(\n",
    "        [np.zeros((280, 10)), images, np.zeros((280, 10))], axis=1\n",
    "    )\n",
    "    images = np.concatenate(\n",
    "        [np.zeros((10, 300)), images, np.zeros((10, 300))], axis=0\n",
    "    )\n",
    "\n",
    "    plt.imshow(images, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.title(\"Visualizing Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Defining the TensorFlow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, (None, config.input_dim))\n",
    "epsilon_binary = tf.placeholder(tf.float32, (None, 50, 2))\n",
    "epsilon_normal = tf.placeholder(tf.float32, (None, 10))\n",
    "\n",
    "temperature = tf.placeholder_with_default(1.0, shape=None, name=\"temperature\")\n",
    "\n",
    "encoder = Encoder(\"encoder\", [\"logits\", \"mean\", \"log_var\"])\n",
    "Z = encoder.build(\n",
    "    [50 * 2, 10],                                             # Dimensions of Latent Variables\n",
    "    [(1000, 500), (500, 200)],                                # Layer Sizes between Latent Variables\n",
    "    [                                                         # Definition of Latent Variables\n",
    "        (priors.DiscreteFactorial(50, 2), epsilon_binary),\n",
    "        (priors.NormalFactorial(10), epsilon_normal)\n",
    "    ],\n",
    "    [[\"logits\"], [\"mean\", \"log_var\"]],                        # Dependence of Latent Variables\n",
    "    [{\"temperature\": temperature}, {}],                       # Additional parameters for reparametrization\n",
    "    X                                                         # Initial Input Variable\n",
    ")\n",
    "\n",
    "decoder = Decoder(\"decoder\", config.latent_type)\n",
    "decoder.build(config.input_dim, config.decoder_layer_sizes, Z)\n",
    "\n",
    "recon_X = decoder.output\n",
    "if datagroup == \"mnist\":\n",
    "    recon_X = tf.nn.sigmoid(recon_X)\n",
    "\n",
    "latent_loss = encoder.kl_from_priors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if datagroup == \"mnist\":\n",
    "    recon_loss = tf.reduce_mean(tf.reduce_sum(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=X,\n",
    "            logits=decoder.output\n",
    "        ), axis=1\n",
    "    ))\n",
    "if datagroup == \"spiral\":\n",
    "    recon_loss = tf.reduce_mean(tf.reduce_sum(\n",
    "        tf.square(\n",
    "            decoder.output - X\n",
    "        ), axis=1\n",
    "    ))\n",
    "\n",
    "    \n",
    "loss = recon_loss + latent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.train.exponential_decay(\n",
    "    learning_rate=config.learning_rate,\n",
    "    global_step=0,\n",
    "    decay_steps=train_data.epoch_len * config.decay_steps,\n",
    "    decay_rate=config.decay_rate\n",
    ")\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Defining functions for Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Reconstruction Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def regeneration_plot(epoch, datagroup, dataset):\n",
    "    path = \"plots/regenerated/%s/%s\" % (datagroup, dataset)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    gs = grid.GridSpec(1, 2) \n",
    "\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "        \n",
    "    if datagroup == \"mnist\":\n",
    "        def reshape(images):\n",
    "            images = images.reshape((100, 28, 28))\n",
    "            images = np.concatenate(images, axis=1)\n",
    "            images = np.array([images[:, x:x+280] for x in range(0, 2800, 280)])\n",
    "            images = np.concatenate(images, axis=0)\n",
    "            images = np.concatenate(\n",
    "                [np.zeros((280, 10)), images, np.zeros((280, 10))], axis=1\n",
    "            )\n",
    "            images = np.concatenate(\n",
    "                [np.zeros((10, 300)), images, np.zeros((10, 300))], axis=0\n",
    "            )\n",
    "\n",
    "            return images\n",
    "\n",
    "        lv_binary, lv_normal = encoder.sample_reparametrization_variables(100)\n",
    "        \n",
    "        orig_X = test_data.data[:100]\n",
    "        recn_X = sess.run(\n",
    "            recon_X,\n",
    "            feed_dict={\n",
    "                X: orig_X,\n",
    "                epsilon_binary: lv_binary,\n",
    "                epsilon_normal: lv_normal\n",
    "            }\n",
    "        )\n",
    "\n",
    "        ax1.imshow(reshape(orig_X), cmap=\"Greys_r\")\n",
    "        ax2.imshow(reshape(recn_X), cmap=\"Greys_r\")\n",
    "        \n",
    "        ax2.spines['left'].set_visible(False)\n",
    "        \n",
    "    elif datagroup == \"spiral\":\n",
    "        recn_X = sess.run(\n",
    "            recon_X,\n",
    "            feed_dict={\n",
    "                X: test_data.data,\n",
    "                epsilon: np.random.randn(len(test_data.data), config.latent_dim)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        ax1.scatter(test_data.data[:, 0], test_data.data[:, 1], s=0.5)\n",
    "        ax2.scatter(recn_X[:, 0], recn_X[:, 1], s=0.5)\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    ax1.spines['left'].set_visible(False)\n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "    ax2.spines['bottom'].set_visible(False)\n",
    "\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path + \"/%s.png\" % str(epoch), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sampling Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_plot(epoch, dataset=\"mnist\"):\n",
    "    if not os.path.exists(\"plots/sampled/\" + dataset):\n",
    "        os.makedirs(\"plots/sampled/\" + dataset)\n",
    "    \n",
    "    gs = grid.GridSpec(1, 2)\n",
    "\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "    \n",
    "    mus, sigmas = sess.run([prior_means, prior_vars], feed_dict={})\n",
    "    \n",
    "    sigmas = np.sqrt(sigmas)\n",
    "    \n",
    "    if dataset == \"mnist\":\n",
    "        sample_Z = list()\n",
    "        decoded_X = list()\n",
    "        for k in range(0, conf.n_clusters):\n",
    "            s_Z = mus[k] + sigmas[k] * np.random.randn(1000, conf.latent_dim)\n",
    "            sample_Z.append(s_Z)\n",
    "\n",
    "            decoded_X.append(sess.run(\n",
    "                decoded_X_mean,\n",
    "                feed_dict={\n",
    "                    Z: s_Z\n",
    "                }\n",
    "            ))\n",
    "\n",
    "        sample_Z = np.concatenate(sample_Z, axis=0)\n",
    "        if conf.latent_dim > 2:\n",
    "            sample_Z = TSNE(n_components=2).fit_transform(sample_Z)\n",
    "        \n",
    "        sample_Z = sample_Z.reshape((conf.n_clusters, sample_Z.shape[0] / conf.n_clusters, 2))\n",
    "\n",
    "        image = (\n",
    "            1 - np.concatenate(\n",
    "                np.concatenate(\n",
    "                    np.array(decoded_X)[:, :10].reshape((10, 10, 28, 28)),\n",
    "                    axis=1\n",
    "                ), \n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ax1.imshow(image, cmap=\"Greys\")\n",
    "\n",
    "        for k in range(0, conf.n_clusters):\n",
    "            ax2.scatter(sample_Z[k][:, 0], sample_Z[k][:, 1], s=0.5)\n",
    "        \n",
    "    elif dataset == \"spiral\":\n",
    "        eps = np.random.randn(conf.n_clusters, 1000, conf.latent_dim)\n",
    "        \n",
    "        sample_Z = np.concatenate([eps[k] * sigmas[k] + mus[k] for k in range(0, conf.n_clusters)])\n",
    "        \n",
    "        decoded_X = [\n",
    "            sess.run(\n",
    "                decoded_exp_X_mean,\n",
    "                feed_dict={\n",
    "                    Z: sample_Z[1000*k:1000*(k + 1)]\n",
    "                }\n",
    "            ) for k in range(0, conf.n_clusters)\n",
    "        ]\n",
    "        \n",
    "        if conf.latent_dim > 2:\n",
    "            sample_Z = TSNE(n_components=2).fit_transform(sample_Z)\n",
    "\n",
    "        for k in range(0, conf.n_clusters):\n",
    "            ax1.scatter(decoded_X[k][:, 0], decoded_X[k][:, 1], s=0.5)\n",
    "            ax2.scatter(sample_Z[1000*k:1000*(k+1), 0], sample_Z[1000*k:1000*(k+1), 1], s=0.5)\n",
    "\n",
    "    ax1.spines['left'].set_visible(False)\n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "    ax2.spines['bottom'].set_visible(False)\n",
    "\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/sampled/\" + dataset + \"/\" + str(epoch) + \".png\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for VAE parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tqdm(range(500), postfix={\"loss\": \"inf\"}) as bar:\n",
    "    for epoch in bar:\n",
    "        if epoch % 5 == 0:\n",
    "            regeneration_plot(epoch, datagroup, dataset)\n",
    "        \n",
    "        J = 0.0\n",
    "        for batch in train_data.get_batches():\n",
    "            lv_binary, lv_normal = encoder.sample_reparametrization_variables(len(batch))\n",
    "            out = sess.run(\n",
    "                [loss, recon_loss, latent_loss, train_step],\n",
    "                feed_dict={\n",
    "                    X: batch,\n",
    "                    epsilon_binary: lv_binary,\n",
    "                    epsilon_normal: lv_normal,\n",
    "                    temperature: 0.1\n",
    "                }\n",
    "            )\n",
    "            J += out[0] / train_data.epoch_len\n",
    "\n",
    "        bar.set_postfix({\"loss\": \"%.4f\" % J})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import qupa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = qupa.PopulationAnnealer(10, 10, num_samples=100, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sess.run(sampler.samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (Machine Learning)",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
